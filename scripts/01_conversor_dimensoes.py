import pandas as pd
import sqlite3
import os
import time
import chardet

# --- CONFIGURA√á√ÉO ---
if os.path.basename(os.getcwd()) == 'scripts':
    BASE_DIR = os.path.dirname(os.getcwd())
else:
    BASE_DIR = os.getcwd()

# Caminhos
CAMINHO_DADOS_BRUTOS = os.path.join(BASE_DIR, 'dados', 'dados_brutos', 'dimensao')
CAMINHO_DB = os.path.join(BASE_DIR, 'dados', 'db')

# Criar pasta db se n√£o existir
os.makedirs(CAMINHO_DB, exist_ok=True)

TABELAS_DIMENSAO = {
    'categorias': {
        'arquivo': 'receita_categoria.csv',
        'chave_primaria': 'cocategoriareceita',
        'descricao': 'Categorias de Receita'
    },
    'origens': {
        'arquivo': 'receita_origem.csv',
        'chave_primaria': 'cofontereceita',
        'descricao': 'Origens de Receita'
    },
    'especies': {
        'arquivo': 'receita_especie.csv',
        'chave_primaria': 'cosubfontereceita',
        'descricao': 'Esp√©cies de Receita'
    },
    'especificacoes': {
        'arquivo': 'receita_especificacao.csv',
        'chave_primaria': 'corubrica',
        'descricao': 'Especifica√ß√µes/Rubricas'
    },
    'alineas': {
        'arquivo': 'receita_alinea.csv',
        'chave_primaria': 'coalinea',
        'descricao': 'Al√≠neas'
    },
    'fontes': {
        'arquivo': 'fonte.csv',
        'chave_primaria': 'cofonte',
        'descricao': 'Fontes de Recursos'
    },
    'contas': {
        'arquivo': 'contacontabil.csv',
        'chave_primaria': 'cocontacontabil',
        'descricao': 'Contas Cont√°beis'
    },
    'unidades_gestoras': {
        'arquivo': 'unidadegestora.csv',
        'chave_primaria': 'coug',
        'descricao': 'Unidades Gestoras'
    }
}

def detectar_encoding(arquivo_path):
    """Detecta automaticamente o encoding do arquivo"""
    with open(arquivo_path, 'rb') as file:
        raw_data = file.read(100000)
        result = chardet.detect(raw_data)
        return result['encoding']

def ler_csv_com_encoding_correto(arquivo_csv):
    """Tenta ler o CSV com diferentes encodings e separadores."""
    encodings = ['utf-8', 'utf-8-sig', 'latin1', 'iso-8859-1', 'cp1252']
    separadores = [';', ',']
    
    detected_encoding = detectar_encoding(arquivo_csv)
    if detected_encoding:
        encodings.insert(0, detected_encoding)
    
    for encoding in encodings:
        for sep in separadores:
            try:
                df = pd.read_csv(arquivo_csv, encoding=encoding, on_bad_lines='skip', sep=sep, dtype=str)
                if len(df.columns) > 1:
                    print(f"   üìù Encoding: {encoding}, Separador: '{sep}'")
                    return df
            except Exception:
                continue
    
    raise ValueError(f"N√£o foi poss√≠vel ler ou parsear o arquivo {arquivo_csv}")

def criar_banco_dimensoes():
    """Cria o banco de dados com todas as tabelas de dimens√£o"""
    
    print("=" * 60)
    print("CONVERSOR OTIMIZADO DE TABELAS DIMENS√ÉO")
    print("=" * 60)
    
    start_time = time.time()
    
    caminho_db = os.path.join(CAMINHO_DB, 'banco_dimensoes.db')
    
    if os.path.exists(caminho_db):
        resposta = input("\nBanco de dimens√µes j√° existe. Deseja substitu√≠-lo? (s/n): ")
        if resposta.lower() != 's':
            print("Opera√ß√£o cancelada.")
            return
        os.remove(caminho_db)
        print("Banco antigo removido.")
    
    # Conecta com configura√ß√µes otimizadas
    conn = sqlite3.connect(caminho_db)
    cursor = conn.cursor()
    
    # Otimiza√ß√µes do SQLite
    cursor.execute("PRAGMA journal_mode=WAL")
    cursor.execute("PRAGMA synchronous=NORMAL")
    cursor.execute("PRAGMA cache_size=10000")
    cursor.execute("PRAGMA temp_store=MEMORY")
    
    print("\n--- Processando Tabelas Dimens√£o ---")
    
    total_registros = 0
    
    for nome_tabela, info in TABELAS_DIMENSAO.items():
        arquivo_csv = os.path.join(CAMINHO_DADOS_BRUTOS, info['arquivo'])
        
        print(f"\nüìÅ {info['arquivo']}:")
        
        if os.path.exists(arquivo_csv):
            try:
                inicio_tabela = time.time()
                
                df = ler_csv_com_encoding_correto(arquivo_csv)
                
                # Converter nomes das colunas para min√∫sculas
                df.columns = [col.lower() for col in df.columns]
                print(f"   - Nomes de colunas convertidos para min√∫sculas")

                # Salva no banco
                df.to_sql(nome_tabela, conn, if_exists='replace', index=False)
                
                # Cria √≠ndice na chave prim√°ria
                chave_primaria = info['chave_primaria']
                if chave_primaria in df.columns:
                    cursor.execute(f"CREATE INDEX IF NOT EXISTS idx_{nome_tabela}_{chave_primaria} ON {nome_tabela} ({chave_primaria})")
                
                tempo_tabela = time.time() - inicio_tabela
                registros = len(df)
                total_registros += registros
                
                print(f"   ‚úÖ Tabela '{nome_tabela}' criada com {registros:,} registros em {tempo_tabela:.2f}s")
                
            except Exception as e:
                print(f"   ‚ùå Erro ao processar: {e}")
        else:
            print(f"   ‚ö†Ô∏è  Arquivo n√£o encontrado!")
    
    # Otimiza o banco ap√≥s todas as inser√ß√µes
    print("\nüîß Otimizando banco de dados...")
    cursor.execute("ANALYZE")
    cursor.execute("VACUUM")
    
    conn.commit()
    conn.close()
    
    end_time = time.time()
    tempo_total = end_time - start_time
    
    print(f"\nüìä Estat√≠sticas finais:")
    print(f"   Total de registros: {total_registros:,}")
    print(f"   Tempo total: {tempo_total:.2f} segundos")
    print(f"   Taxa m√©dia: {total_registros/tempo_total:.0f} registros/segundo")
    print(f"\nüíæ Banco de dimens√µes criado em: {os.path.abspath(caminho_db)}")

if __name__ == "__main__":
    criar_banco_dimensoes()